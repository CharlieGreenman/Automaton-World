# CHAPTER ONE: THE LAST NORMAL YEAR

### *Three people on the eve of everything*

Elena notices it on a Tuesday.

Not a dramatic Tuesday. Not the kind of morning that the story would later require it to be. It is overcast, mid-November, and she has been in the lab since seven because her postdoc Benjamin has been struggling with a protein folding analysis for three weeks and she promised to look at it fresh. She pours coffee, opens the system dashboard, and begins reviewing the AI research assistant's overnight outputs.

The system — her institution's licensed version of a research platform that had been making steady incremental improvements for three years — had been tasked with surveying the literature for mechanisms related to a particular inflammatory pathway. Standard work. The kind of task she assigned it regularly: broad literature sweep, flagged connections, synthesis of what was known. She expected forty or fifty pages of organized results, properly cited, that her team would spend the week reading.

What she finds is a hundred and twelve pages. And the last eight pages are not synthesis. They are speculation.

The system has flagged them as such, honestly, at the top of the section: *The following represents hypothetical connections not directly supported by existing literature, generated from pattern analysis across multiple subfields.* Then it proceeds to propose three mechanisms that the literature had not connected, backed by reasoning that draws from immunology, structural biology, and a 2019 epidemiological study in a Scandinavian registry that Elena remembers reading once and never thinking of again.

She reads the three proposed mechanisms carefully. One of them is almost certainly an artifact of the model — the reasoning looks right but the underlying assumption about membrane permeability is probably wrong. She makes a note. The second one she needs to check; it is possibly interesting. The third one stops her.

The third one is not just interesting. It is, if the reasoning holds, potentially important. It connects a receptor her team has been studying to a cytokine signaling pathway in a way that nobody — not in her field, not that she has seen — has proposed. And the reasoning is not exotic. It is careful, specific, supported by citations she can verify, and it ends with: *Experimental validation would require...* followed by a protocol that is, actually, feasible.

She sits back.

She is not threatened. That is not the right word for what she feels. She is something more complex: she is admiring and she is unsettled simultaneously, in the way that you feel when you encounter a student who is better than you in a specific way that you had not expected. Not better overall. Not better at the thing you are best at. Better at one thing you thought was yours.

She calls Benjamin in and shows him the pages.

He reads the third proposed mechanism and his face does what faces do when a real idea appears in them. "Huh," he says. Then: "Has anyone ever tried this?"

"I need to check," she says.

He is already at his terminal.

---

David gets the call on a Wednesday afternoon in March.

He has been expecting some version of this call for eighteen months, since the supply chain AI tools started appearing in his industry trade publications. But expecting something in the abstract and receiving it in the specific are different experiences, and the specificity of this particular call — Maria's voice, the particular way she says "David" before she says anything else, the pause that follows it — is harder than he expected.

Maria runs operations for a mid-size industrial equipment manufacturer in Ohio that has been one of David's best customers for four years. She is a deliberate person who chooses her words carefully and who, in four years of calls and site visits and the occasional dinner, has never said anything that David later found untrue.

"I want to be straight with you," she says.

"Please."

"We're running a pilot with a new system. I want you to understand what I'm seeing."

He listens. She is precise, as she always is. The system she is describing — built by a company that had been operating for eighteen months with a team of twelve people, none of whom David has heard of — is performing what she describes with the careful neutrality of someone who genuinely does not want to be cruel. It is not that the system is faster, though it is. It is not that it is cheaper, though it is. It is that the system has understood the structural problems of her supply chain — the underlying architecture of how her materials flow and where they jam and what the actual sources of variance are — in a way that David's platform, which is good at everything Maria had been able to articulate as a problem, had not been equipped to even see.

"How long did it take?" David asks.

"To understand the problems?"

"Yes."

Another pause. "Four hours. Initial scan. Then it spent a week running scenarios."

David has been building platforms that helped companies like Maria's manage supply chain complexity for seven years. The best implementations he had done — the ones where he had really gotten inside a customer's operations, where he had spent days on the floor understanding the specific ways that their specific problems were specific — had taken months to produce insight of this depth. And he had been proud of those implementations. He had been right to be proud of them. They were genuinely good work.

"I understand," he says.

"I'm sorry," Maria says. And she is. He can hear it.

After he hangs up, he sits at his desk for a long time. His office overlooks the street outside — pedestrians, a delivery vehicle navigating a double-parked car, a woman walking a dog with the distracted certainty of someone whose mind is entirely elsewhere. He watches the street. He thinks about his sixty-one people. He thinks about what he is going to say to them, and when, and how honestly.

He does not feel rage. He does not feel despair. He feels something that is harder to name: the particular grief of a person who built something real and true and useful, and who has just been told that the problem his real and true and useful thing was solving will no longer be his problem to solve.

The grief passes through him. He lets it. Then he opens a new document and begins to type: things he has learned from seven years of building at the intersection of software and industrial operations, things that might be worth writing down for reasons he cannot yet articulate.

He fills three pages before he realizes he has been writing for two hours.

---

Maya knows something is changing because Daniel asks her a question she cannot answer.

Daniel is eight years old and has the quality of attention that teachers love and find slightly unnerving: when he is interested in something, he is completely interested, and when he is not, he is completely elsewhere, and there is nothing gradual about the transition between the two states. He was interested in dinosaurs for six weeks in September and October. He was interested in maps for three weeks in November — not countries, not geography exactly, but the idea of what maps are: representations of terrain that are not terrain, and what gets lost in the representation. He asked Maya about this directly one morning, unprompted, in the way that children ask things that they have been sitting with for days: "A map isn't the same as the place, right? Like you can't walk on a map."

"Right," she said.

"So why do we think the map is the same as the place?"

She had no answer for this that fully satisfied either of them.

In December, Daniel becomes interested in the question that will not, for Maya, fully go away for years afterward. It begins during a math lesson — long division, which she teaches because it is in the curriculum and because it does develop a real kind of precise sequential thinking that has value, though the value is harder to articulate than the steps themselves. The lesson is going well; most of the class is following along. Daniel is following along, clearly, but his face has the specific look it gets when he is also doing something else internally — processing something alongside the lesson rather than inside it.

When the lesson ends and she gives the class time to work through the worksheet, he raises his hand.

"Mrs. M," he says, "why are we learning to do this?"

"Long division?"

"Yeah. Like — I can just ask the computer and it does it. And it never gets it wrong."

"It trains your brain to think in careful steps," she says. "That kind of precise thinking is useful."

"But couldn't I just do other things that train careful thinking? Things the computer can't do?"

She looks at him. He is eight years old. He is not being difficult. He is genuinely asking.

"That's a really good question," she says, which is the true thing and also the deflection.

She thinks about this question for the rest of the afternoon, through two more classes and a parent meeting and the drive home in the gray December dark. She is not a philosopher and does not think of herself as one. She is a teacher who loves children and who takes seriously the proposition that what she does with them every day matters. But she has been feeling, for the better part of this year, a low-frequency unease that she has not been able to name until now, and Daniel's question names it precisely.

*What am I teaching them for?*

Not in the nihilistic sense. Not because she doubts that children should be educated. But in the most literal sense: what is this education for? The honest answer, which she had always assumed without examining it, is that it prepares children for productive adult life — gives them the skills and the habits and the credentials that allow them to contribute to the world's work in ways the world values.

But what if the world's work is changing so completely that the preparation she is providing is preparation for a world that will not exist?

She does not panic. She is not a person who panics. She sits with the question the way that Daniel sits with questions, with the complete attention of someone who understands that the question is more important than the discomfort of not having an answer.

She pulls out the yellow legal pad she uses for non-school thinking and writes the question at the top in her careful, elementary-school-teacher's handwriting: *What are we teaching them for, if the machines can do what we're teaching them to do?*

She stares at this for a long time.

She does not write an answer.

---

## The Texture of the Last Normal Year

What I want to convey about 2027 is the specific quality of the strangeness: that it is not yet strange enough to be called strange. The routines hold. The meetings happen. The year looks, from the outside and most of the inside, like any other year — like the years before it, with the same seasonal rhythms and the same ambient arguments and the same diversions and the same ordinary pleasures.

And yet.

Something is in the air that is not quite alarm but is not quite comfort either. The people who are paying close attention — who are in the fields closest to the change, who are honest with themselves about what they are seeing — feel it as a persistent alertness, a sense of standing on ground that is stable now but that they cannot quite trust will be stable tomorrow. Not fear. Not excitement. Something that contains both.

The economists are arguing, as they have been arguing for ten years, about whether this round of automation will be different. The confident ones, the ones who get the conference invitations, say it will not: every previous wave of automation created more jobs than it destroyed, and there is no reason to think this one will be different. The less confident ones, who tend to get published in journals rather than invited to conferences, are beginning to accumulate evidence that this wave is not like the previous ones in ways that matter. The arguments are technical and the technical arguments are proxies for a deeper disagreement about what kind of thing human intelligence is and whether it is, in principle, substitutable.

The people who do not follow the economists are having a different version of the argument, less formal and more immediate. In the break rooms and the family dinners and the late nights when the phone won't distract enough — people are talking about what is changing and what it means and what they should do. Not with answers, mostly. With the particular attention of people who sense that the questions they are asking now are going to become the most important questions of their lives.

---

## What Elena Does With Her Discovery

She checks the literature. Carefully, with Benjamin's help, over three days. The proposed mechanism in the AI's speculation has not been proposed before — not exactly, not in the form the system laid it out. There are adjacent ideas. There is work that, in retrospect, gestured toward it. But the specific synthesis is new.

She designs an experiment to test it. The experiment is possible with her current lab capacity, though it will take several months. She begins the process. She does not tell anyone outside the lab yet — not because she is secretive but because she has been wrong before and would like to know whether she is wrong again before she announces anything.

She also does something else. She begins to pay different attention to the AI system's outputs. Not the synthesis sections — those she had always read carefully. The speculations. The sections it flags honestly as hypothetical. She starts treating these the way she treats the suggestions of a smart junior colleague: with the specific kind of skepticism that is not dismissal but engagement, that asks *why do you think this?* rather than *prove it*.

It is, she realizes gradually, a different kind of working relationship than any she has had before. The system is not conscious. It does not care about the science in the way she cares about it. It has no intuitions in the phenomenological sense. And yet. When she treats its speculations seriously, and asks the questions they generate, and pursues the experimental implications with genuine rigor — something happens that she does not have good words for. The science gets better.

She writes this observation in her journal, carefully. She does not know what to do with it yet. She stores it the way good scientists store things they do not yet understand: precisely, without interpretation, in a place she can find again.

---

## What David Does With His Grief

He writes down what he knows.

This surprises him. He has always been a builder, not a writer — an action person, most comfortable when he is moving toward something rather than reflecting on what he has already moved through. But the document he starts on the afternoon of the Maria call continues to grow over the following weeks, filling with observations about the specific kinds of problems that were interesting in supply chain operations and why they were interesting, about the ways that organizations resist knowing what their problems actually are versus what they say their problems are, about the difference between the problems that technology solved well and the problems that required sustained human relationship to solve at all.

He is not sure why he is writing this. He does not have an audience in mind. He is doing what he does when he is genuinely uncertain: gathering data, organizing observation, looking for the pattern.

Somewhere in the third week of this process he starts to notice something. The problems that required sustained human relationship to solve — the ones that needed someone who understood an organization's culture well enough to know what information people would and wouldn't share, who knew which VP's concerns were political and which were substantive, who could read a room and adjust in real time — these are not the problems the new system is solving. The new system is extraordinary at optimization, at pattern recognition, at finding the structural inefficiency in a supply chain that can be quantified and modeled. It is not, as far as he can tell, good at the political and relational work of getting organizations to be honest about what their actual problems are.

This observation will take him years to fully develop. In 2027, it is just an observation, carefully written down, in a document that doesn't have a title yet.

---

## What Maya Does With Her Question

She brings it to the other teachers.

Not as a crisis — she does not frame it that way, because that is not how she experiences it and she is careful about how she models the relationship to uncertainty for the adults she works with. She brings it as a genuine inquiry: what do we think we are teaching children for, and is our answer still right?

The conversations that follow are some of the most interesting she has had in her decade of teaching. Her colleagues have their own versions of the question. The reading specialist who has spent twenty years developing interventions for dyslexic readers has been watching the new text-to-speech and comprehension assistance tools develop with a feeling she cannot categorize as either threat or relief. The science teacher who loves the physical demos — the vinegar and baking soda, the pendulum, the Van de Graaff generator that makes everyone's hair stand up — has been wondering why he requires students to memorize the periodic table when they can ask any device to produce it instantly. The art teacher, surprisingly, seems the least troubled: "Art was never about the output," she says, in a way that makes Maya feel she has missed something obvious.

What Maya takes from these conversations is not an answer but a sharpened version of the question. The teachers who seem most settled are not the ones who think the change won't affect them. They are the ones who have always understood — consciously or not — that what they were teaching was not primarily content. That the point was something harder to name and harder to displace: the experience of sustained inquiry, the development of the habit of paying attention, the particular formation of a person that happens when they encounter genuine difficulty in the presence of someone who does not panic about the difficulty.

Maya had been teaching this, she realizes. She had not known that was what she was teaching, exactly. She had not had the vocabulary for it.

She starts looking for the vocabulary. She reads things she has not read before: philosophy of education, cognitive science, the writings of teachers whose work she has always respected but whose frameworks she has never formally studied. She is doing this in the evenings after her children are asleep, in the forty minutes she allows herself before bed, with the particular focus of someone who has found the question that organizes her.

She does not know, in 2027, that this question will become the work of her life. She does not know that she will spend the next fifteen years building a model for education that takes Daniel's question seriously — that asks what learning is for when the machines can do what we have been teaching children to do, and answers it with something that Daniel, at eight, had already intuited was the right direction.

She just knows the question matters. And she keeps going toward it.

---

## The Last Normal Year, Ending

The year ends in the ordinary way. Schools close for winter break. David's company has its Christmas party, smaller than last year's, the mood careful and kind in the way that moods are when everyone is carrying something they have agreed not to say. Elena submits a grant renewal, which requires justifying the human portion of the research team now that AI systems are doing more of the computational work — a form that did not exist three years ago and whose existence she finds telling. Maya's third-grade class performs its winter concert; the parents who can make it come; Daniel sings in the back row with the solemn intensity he brings to everything.

The routines hold. The year turns. The cascade has not yet arrived.

But the people who are paying attention know it is coming. They have not calibrated how fast, or how complete, or what it will actually feel like on the inside. Nobody has. But they know the direction, and they are already, in their separate ways, trying to understand what is real and worth keeping in the world as it is, before the world as it is becomes the world as it was.

This is the last thing to say about the last normal year: that the people in it were not asleep. The ones who mattered — who would turn out to matter — were awake. Carefully, specifically, humanly awake to what was coming.

It made the difference that it always makes: not to the event itself, which arrived on its own schedule regardless. But to who the people were when it arrived, and what they could do with it when it came.

---
