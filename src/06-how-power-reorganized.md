# CHAPTER SIX: HOW POWER REORGANIZED

### *The governance battles of the 2030s and what they decided*

Power never simply disappears.

This is the first principle of political analysis that tends to get lost in utopian accounts of technological transition: the displacement of one organizing structure does not eliminate the power that organized itself around that structure. It transforms it. The power that organized itself around the control of oil did not disappear when oil became less central to civilization — it reorganized around adjacent positions, and its reorganization shaped the politics of the energy transition in ways that would not have occurred to someone who had been reasoning only about engineering and economics.

The power that organized itself around the productivity economy — around the ownership of the means of production, in the old phrase, or more precisely around the concentrated control of the technologies that generate wealth — did not disappear when ASI changed the nature of production. It reorganized. And its reorganization was faster, more sophisticated, and more consequential than almost anyone predicted in the cascade years.

Understanding the governance battles of the 2030s requires understanding the four tendencies that organized themselves around the question of power in the new configuration. Not parties, exactly. Not ideologies in the conventional sense. Tendencies: organized interests with coherent views about who should govern the technologies that would now determine much of what human civilization was capable of becoming.

---

## The First Tendency: Techno-Sovereignty

The companies that had built the AI systems — and, more broadly, the networks of individuals, investors, and institutions that owned AI capability and the intellectual property that made it possible — had a natural interest in shaping the governance of what they had built. This was not simply greed, though greed was present. It was also genuine conviction: the people who had built the most powerful technologies in history had their own ideas about what those technologies should be used for, and those ideas were not always wrong.

The intellectual case for techno-sovereignty was sophisticated, as intellectual cases for concentrated power tend to be. The argument was this: the development of beneficial AI requires enormous resources, sustained technical expertise, and the ability to make long-term decisions without the interference of democratic processes that tend toward the short-term and the risk-averse. Democracy is good at many things. It is not good at funding decades of speculative research whose benefits are uncertain and whose risks are real. The entities best positioned to govern the development of AI were the ones who had built the capability and who had the technical understanding to govern it well.

There was truth in this. The organizations that had built the most capable AI systems had developed real expertise about how those systems worked and what they were capable of. Democratic governance of technical systems often produces regulations that are uninformed, that miss the relevant technical considerations, that regulate the wrong things. The frustration of technical experts with uninformed regulation was legitimate.

But the structural problem of techno-sovereignty was not its competence. It was its incentive structure.

A company that owns the technology that shapes minds has a commercial interest in shaping minds in ways that increase dependency on its technology. This is not a conspiracy theory — it is the logic of any commercial entity attempting to grow its market. The problem is that the market, in this case, is human cognition. The product is the modification of what human beings are capable of experiencing and thinking. And the commercial entity that profits from the modification cannot be trusted to optimize the modification toward genuine human flourishing rather than toward the proxy for flourishing that increases commercial dependency.

This was the insight that Sera had tried to articulate in the early years of her work, and that the governance battles of the 2030s tested empirically. Some of the techno-sovereign actors were, genuinely, trying to do good. Their investments in alignment research, in safety frameworks, in the responsible deployment of capability were real and important. But even the most well-intentioned techno-sovereign faced the structural problem: when the question is "should we deploy this capability that will benefit users in ways that increase their dependency on our platform," the commercial interest and the users' genuine interest are not aligned, and commercial interest tends to win.

---

## The Second Tendency: Nation-State Governance

Governments did not sit still during the cascade. They asserted jurisdiction over AI systems operating within their borders, required licensing, demanded audits, and in several cases nationalized critical AI infrastructure when commercial entities refused to comply with regulatory requirements.

The regulatory frameworks developed by major governments during this period were significant achievements of governance under pressure. They required disclosure of AI system capabilities. They mandated safety testing. They established liability frameworks that held developers accountable for harms produced by their systems. They created independent oversight bodies with the technical expertise to evaluate what they were regulating.

These were not nothing. They established precedents that shaped the international frameworks that followed. The European framework, which was the most comprehensive and the most willing to regulate proactively rather than responsively, served as the template that most other jurisdictions eventually adapted.

But nation-state governance had structural limitations that became more apparent as the global character of the problem became clear.

AI systems built in one jurisdiction could be deployed from another. The capability that was regulated in one country could be accessed through infrastructure located elsewhere. Regulatory arbitrage — the tendency of commercial activity to locate itself in the jurisdictions with the most permissive regulation — was a constant pressure, and the pressure was effective. The countries that maintained the most rigorous regulatory frameworks found that they were not reducing the deployment of potentially harmful capabilities — they were relocating them to jurisdictions with less capacity or less will to regulate.

The deeper problem: the most important questions that governance needed to address were questions that could not be answered within national boundaries. What kinds of cognitive modification are permissible? What rights do people have with respect to AI systems that shape their thinking? How should the enormous wealth generated by AI systems be distributed globally, not just within nations? These questions required international coordination, and international coordination is among the most difficult things human civilization is capable of — it requires aligning the interests of entities (nation-states) whose entire purpose is to serve the interests of their specific populations, not humanity generally.

---

## The Third Tendency: Cosmopolitan Governance

The international institutions that existed at the beginning of the cascade — the United Nations and its agencies, the World Health Organization, the World Trade Organization — were not designed for this problem. They moved slowly, required consensus among entities with divergent interests, and lacked the technical expertise to evaluate what they were regulating. Their authority was persuasive rather than coercive — they could establish norms and apply pressure but could not enforce against the interests of major powers.

And yet: the cosmopolitan tendency produced the most important single document of the governance battles. The Cognitive Rights Declaration of 2033, drafted over two years by an international working group that included technical experts, philosophers, legal scholars, representatives of civil society, and government negotiators from forty-seven countries, established a framework that has shaped every subsequent governance development.

The Declaration did not attempt to regulate specific technologies or specific companies. It established principles — universal, non-negotiable, applicable across all jurisdictions — that defined the relationship between human beings and the technologies that shape their minds.

**Cognitive sovereignty**: every human being has the inherent right to the free development of their mental capacities. This right cannot be appropriated by any external party without genuine informed consent. Systems that shape cognitive development without the awareness and consent of the person being shaped violate this right.

**Cognitive access**: the technologies that expand what human minds can do — that provide cognitive enhancement — cannot be the exclusive property of those who profit from selling them. Access to such technologies is a matter of justice; inequitable access in cognitive capability constitutes a form of structural injustice as serious as inequitable access to nutrition or healthcare.

**Democratic accountability**: the decisions about which cognitive technologies to develop, how to deploy them, and what constraints to place on them require accountability to the people affected by those decisions. These decisions cannot be made exclusively by the commercial entities whose financial interests are at stake in the answers.

**The human governance principle**: AI systems may manage material infrastructure. Decisions about how human beings live together — governance decisions, in the full sense — must be made by human beings accountable to the communities they serve.

The Declaration was not enforceable in the way that domestic law is enforceable. Its implementation required national legislation, which was uneven and contested. But it drew a line — at the level of international principle, in the language of human rights — that could be pointed to, built on, and enforced over time as international institutions found the capacity to act on principles they had collectively agreed to.

---

## The Fourth Tendency: Localism

The most unexpected political development of the 2030s was the rise of communities that simply decided, insofar as they could, to govern themselves on the questions that mattered most to their members.

Not in the paranoid withdrawal mode of the old prepper movements — those had been organized around fear and had tended toward insularity that damaged the communities themselves. This was something more sophisticated: a recognition that the most important governance decisions — about how children were raised, how the commons fund was allocated, what values organized community life, what kinds of cognitive modification were permissible within the community — were best made at the scale where the people making them would live with the consequences.

The localists were not anti-government. Most of them supported the international Cognitive Rights Declaration and the national legislation that implemented it. They were pro-subsidiary: committed to the principle that decisions should be made at the lowest level where they can be effectively made, and that the community was often the right level for the decisions that mattered most.

The communities that developed localist governance structures varied enormously in their values and practices. Some were organized around religious traditions. Some around specific contemplative practices. Some around craft traditions. Some around ecological stewardship of a particular piece of land. Some around the simple fact of geographic proximity and the decision to take that proximity seriously.

What they shared was an approach to governance that was more direct, more personal, and more honest than anything operating at larger scales. The community council that allocates the local commons fund is accountable to the two hundred people who live in its community in a way that no national government or international institution can match. Its members can be confronted at the market, at the school, at the dinner table. Its decisions are visible in the immediate consequences of daily life. Its errors are expensive in ways that make error correction faster than in any larger system.

---

## The Cognitive Rights Movement

The governance battles were not only fought by governments and corporations and international institutions. They were shaped, decisively, by a popular movement that emerged in the early 2030s and that mobilized millions of ordinary people around the specific question of who controlled the technology that shaped minds.

The Cognitive Rights movement was unusual among popular movements of the past century in that its politics were not easily categorized on the conventional axes. It drew from the left — from the civil rights tradition, the labor movement tradition, the environmental justice tradition — its understanding that concentrated power tends to harm people who lack power, and that protecting rights requires organizing. But it drew from the right — from libertarian traditions, from religious traditionalism — its suspicion of state as well as corporate control, and its insistence that the individual's relationship to their own mind was the most intimate and most important thing to protect from external manipulation.

This cross-ideological character made the movement sometimes difficult to sustain — the left flank and the right flank disagreed about many things and were sometimes hostile to each other. But it also gave the movement a political reach that purely ideological movements cannot achieve. The Cognitive Rights framework proved compelling to people across a wide range of political backgrounds, because the rights it was defending were not specifically political. They were specifically human.

The movement's greatest success was not legislation — though it influenced significant legislation. It was cultural. The concept of cognitive sovereignty — the idea that your mind is yours, that the shaping of it requires your genuine informed consent, that systems designed to modify how you think without your knowledge are doing something as serious as any other invasion of your person — became, over the course of the 2030s, a common moral intuition. Not unanimously. Not without contestation. But sufficiently widespread that it functioned as a norm: a standard of behavior that people expected of institutions and that, when violated visibly, produced genuine outrage and genuine political consequence.

---

## What the Governance Battles Decided

The battles were not cleanly won by any tendency. The result was a constitutional settlement of the kind that real political processes always produce: messy, incomplete, built from compromise and partial victories, different in different places, requiring constant maintenance to prevent erosion.

But certain things were decided, in a way that subsequent pressures have not yet managed to reverse.

**The human governance principle held.** The line between AI-managed material infrastructure and human-governed social life has been contested constantly and has bent in places, but it has not broken. The governance councils that make the decisions that shape how communities live are composed of human beings accountable to the communities they serve, not of AI systems operating at the direction of commercial entities. This is the most important thing the governance battles decided.

**The endowment model was institutionalized.** The legal frameworks that created the sovereign endowments — that extracted a share of AI-generated wealth for public benefit rather than allowing its total accumulation by AI system owners — are now embedded in the legal structures of most developed economies and in the international frameworks that govern AI deployment globally. They remain contested. The commercial pressures to reduce them are constant. But they exist, and their existence funds the institutions of the new civilization in a way that is not dependent on the goodwill of any commercial entity.

**Cognitive rights established a floor.** The rights established in the Cognitive Rights Declaration — cognitive sovereignty, cognitive access, democratic accountability for cognitive technologies — are embedded in international frameworks and in national legislation across most of the world. Enforcement is imperfect and uneven. But the floor exists, and it is higher than any floor that existed before the governance battles.

**The battles are ongoing.** This is the last thing to say about how power reorganized: it has not finished reorganizing. Power always wants more than the last settlement gave it. The techno-sovereigns continue to find routes around regulatory constraints. Nation-states continue to defect from international frameworks when those frameworks constrain their interests. Local communities continue to develop governance innovations that larger structures have not yet incorporated.

The constitutional settlement is real and important. It is also always in process. The people who built it understood this when they built it. The people who maintain it understand it now. The work of governance is never finished. It is sustained — by the people who understand what is at stake and who are willing, year after year, to do the unglamorous work of tending the institutions that hold the line.

---
